---
title: "Gerber and Green Experiment"
output:
  pdf_document:
    keep_tex: TRUE
    template: default.latex
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE)
library(haven)
library(VIM)
library(scales)
library(knitr)
library(dplyr)
data <- read.csv("../data/GreenGerberNickerson_JP_2003.csv", stringsAsFactors = F)

```

# Gerber and Green (2003)
In this appendix, I first describe the experimental data from the paper. The original sample size for the experiment consists of `r nrow(data)` individuals from 6 different cities in the United States.


## Data preparation

### Variables

The dependent variable `voted00`  tells us whether the person voted in the 6 November election in 2001. The treatment indicator `treatmen`  tells us whether the individual was encouraged to be visited by the canvassers. Additionally, the experiment records six background variables about every individual; race, sex, age, party affiliation, turnout in the 2000 election and turnout in the 1999 election.

```{r Setup, include=FALSE}
y <- data$voted01[data$city != 'COLUMBUS']
x <- data[data$city != 'COLUMBUS', c('race', 'sex', 'age', 'party', 'voted00')]
d <- data$city[data$city != 'COLUMBUS']
d <- factor(d, labels =c('Bridgeport', 'Detroit', 'Minneapolis', 'Raleigh', 'St Paul') )
t <- data$treatmen[data$city != 'COLUMBUS']
data_analysis <- cbind(y, x, t, d)
rm(y, x, t, d)
```


In our prediction problem using the experimental data, we do not use the 1999 election variable. According to our knowledge, no elections ocurred in all of the concerned cities in 1999.

### Missing data

There is missing data in the experimental data. In R, the missing data was first recoded to the R's standard NA format and the patterns are visualised in the Figure ().

```{r Missing values to NA, include=FALSE}
data_analysis[data_analysis == ""] <- NA
```


```{r Aggregate plot for missingness}
aggr(data_analysis[2:6])
```

Rather than looking at aggregate patterns of missingness, what is more of an interest for our specific case are the patterns of missing values in each of the locations. We proceed with complete case analysis for cases where the missingness is ~1% on a covariate for a given location. The table below shows the proportion of missing values for a given covariate for every location. 

```{r Missing values per city, echo=FALSE}
cities <- unique(as.character(data_analysis$d))
tab <- data.frame()

for (i in cities) {
  p <- aggr(data_analysis[data_analysis$d == i, 2:6], plot = F)
  tab <- tab %>% bind_rows(., as.data.frame(t(p$missings))[-1, ])
}



tab <- sapply(tab, as.numeric)
tab <- as.data.frame(tab)
rownames(tab) <- cities

vlookup <- numeric()
  
for (i in cities) {
  vlookup <- append(vlookup, length(data_analysis$t[data_analysis$d == i]))
}

tab$numOfObs <- vlookup
tab <- apply(tab, 1, function(x) {
   x/ x['numOfObs']
})

tab <- t(tab)
tab <- as.data.frame(tab)
tab <- tab[, -6]
tab <- tab * 100

kable(tab, booktabs = T, digits = 2)

rm(p, tab)
```

```{r Missing data handling, include=FALSE}
nrow_before <- nrow(data_analysis)

# Bridgeport
# Get rid of the 2 missing values in Age
data_analysis <- data_analysis[!(data_analysis$d == 'Bridgeport' & is.na(data_analysis$age)), ]

# Detroit
# 55 missing values in Detroit
data_analysis <- data_analysis[!(data_analysis$d == 'Detroit' & is.na(data_analysis$sex)), ]

# ST Paul
# 7 missing values in Age
data_analysis <- data_analysis[!(data_analysis$d == 'St Paul' & is.na(data_analysis$age)), ]

# Raleigh
# 14 Missing values in sex
data_analysis <- data_analysis[!(data_analysis$d == 'Raleigh' & is.na(data_analysis$sex)), ]

```

In the complete case analysis we dicarded `r nrow_before - nrow(data_analysis)` rows from the dataset. 

### Other data transformations
As the next step in the data transformation process, we delete one invalid data observation with the value of 2001 for age.

```{r Delete age 2001, include=FALSE}
data_analysis <- data_analysis[!data_analysis$age == 2001, ]
```

Additionally, we reclassify subjects who answered with Unknown to their sex to 'NA' and excluded. This simplifies the matching procedure since with only two sexes, the variable can be operationalised as a dummy variable.

## Data exploration

### The varying individual characteristics between locations
This 

#### Age and Voting in the 2000 election
```{r Table 2 in the paper [Age, Voted00]}
table2 <- data.frame()


for (i in cities) {
  r <- sapply(data_analysis[data_analysis$d == i, c('age', 'voted00')], function(x) {
    mean(x)
  })
  
  table2 <- bind_rows(table2, r)
  
}

rownames(table2) <- cities

table2 <- t(table2)

kable(table2, digits = 2, booktabs = T)

```

#### Sex
```{r Sex, echo=FALSE, warning=FALSE}
# Raleigh
r <- table(as.character(data_analysis$sex[data_analysis$d == 'Raleigh'])) / sum(table(as.character(data_analysis$sex[data_analysis$d == 'Raleigh'])))

# Bridgeport 
b <- table(as.character(data_analysis$sex[data_analysis$d == 'Bridgeport'])) / sum(table(as.character(data_analysis$sex[data_analysis$d == 'Bridgeport'])))

# Detroit
d <- table(as.character(data_analysis$sex[data_analysis$d == 'Detroit'])) / sum(table(as.character(data_analysis$sex[data_analysis$d == 'Detroit'])))

tab <- bind_rows(r, b, d)
rownames(tab) <- c('Raleigh', 'Bridgeport', 'Detroit')

kable(tab, digits = 2, booktabs = T)
```

#### Party affiliation
```{r Party affiliation, echo=FALSE, warning=FALSE}
# Raleigh
r <- table(as.character(data_analysis$party[data_analysis$d == 'Raleigh']))/ 
  sum(table(as.character(data_analysis$party[data_analysis$d == 'Raleigh'])))
# Bridgeport
b <- table(as.character(data_analysis$party[data_analysis$d == 'Bridgeport'])) / sum(table(as.character(data_analysis$party[data_analysis$d == 'Bridgeport'])))

tab <- bind_rows(r, b)
tab <- tab[c('D', 'I', 'R')]
rownames(tab) <- c("Raleigh", "Bridgeport")

kable(tab, digits = 2, booktabs = T)
```

```{r Export the cleaned data, include=FALSE}
saveRDS(data_analysis, file = '../data/gg_clean.Rds')
```

## Further causalMatch specifications
In the operationalisation of causalMatch to the experimental data in the dissertation we have rescaled the age variable to be in the range 0 to 1. Here, I provide two other additional options of working with the variable. First, I scale the age variable by dividing it by its root-mean-square defined as $\sqrt{\frac{1}{n}\sum_{t=1}^{n}age_t^2}$. The results can be seen in the table below.

|             | $\tau_{ITT}^{PRED}$  | $\hat{\tau_{ITT}}$  | SE     | $\tau_{ITT}^{NAIVE}$  | NPE    |
| :---------- | -------------------: | -------------------: | -----: | --------------------: | -----: |
| Bridgeport  | 2\.29                | 3\.84                | 2\.42  | 2\.01                 | 3\.37  |
| Raleigh     | 2\.76                | -0\.90               | 13\.38 | 3\.19                 | 16\.77 |
| Detroit     | 1\.56                | 2\.47                | 0\.83  | 2\.35                 | 0\.02  |
| Minneapolis | 3\.46                | 1\.99                | 2\.18  | 2\.47                 | 0\.23  |
| St Paul     | 3\.65                | 4\.47                | 0\.67  | 1\.85                 | 6\.87  |


Finally, the table below presents the unscaled results. In this case, no transformation was applied to the age variable. 


|             | $\tau_{ITT}^{PRED}$  | $\hat{\tau_{ITT}}$  | SE     | $\tau_{ITT}^{NAIVE}$  | NPE    |
| :---------- | -------------------: | -------------------: | -----: | --------------------: | -----: |
| Bridgeport  | 2\.97                | 3\.84                | 0\.77  | 2\.01                 | 3\.37  |
| Raleigh     | 2\.91                | -0\.90               | 14\.57 | 3\.19                 | 16\.77 |
| Detroit     | 1\.68                | 2\.47                | 0\.63  | 2\.35                 | 0\.02  |
| Minneapolis | 3\.45                | 1\.99                | 2\.14  | 2\.47                 | 0\.23  |
| St Paul     | 3\.63                | 4\.47                | 0\.70  | 1\.85                 | 6\.87  |


Compared to the table presented in the main body of the dissertation (see Table ), the different specification of scaling does not alter our conclusion that we can predict the ITT more accurately than using the naive method in four out of six cases. 